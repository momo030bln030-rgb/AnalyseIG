# Facebook & Instagram Scraper Tools - QUICK START GUIDE

## üìÅ √úbersicht der Skripte

### **INSTAGRAM Tools**
```
1. ig.py                    - Original Instagram Scraper mit Login
2. ig_working.py            - Verbesserte Basis-Version
3. ig_complete.py           - VOLLST√ÑNDIGER Scraper (empfohlen)
   ‚îî‚îÄ Posts, Kommentare, Likes, Hashtags, Erw√§hnungen, Engagement
```

### **FACEBOOK Tools**
```
1. facebook_analyzer.py      - Basis-Analyzer (Name-Suche + Profil)
2. facebook_advanced_scraper.py - ERWEITERT mit Umgehungstechniken
   ‚îî‚îÄ Archive.org, Google Cache, Reverse Image Search, Filter-Suche
```

---

## üöÄ SCHNELLSTART

### Instagram - Posts & Kommentare abrufen
```bash
cd c:\Users\MoMo-Bln\Downloads\Music\ig
python ig_complete.py
```
**Dann √§ndern (Zeile ~365):**
```python
target_username = "cristiano"  # Dein Ziel-Account
```

### Facebook - Profil suchen & analysieren
```bash
python facebook_analyzer.py
```
**Dann √§ndern (Zeile ~470):**
```python
search_name = "Max Mueller"  # Name zum Suchen
```

### Facebook - FORTGESCHRITTENE ANALYSE
```bash
python facebook_advanced_scraper.py
```
**Nutzt:**
- Archive.org (gel√∂schte Inhalte)
- Google Cache (√§ltere Versionen)
- Reverse Image Search
- Erweiterte Filter-Suche

---

## üéØ ANWENDUNGSBEISPIELE

### Beispiel 1: Instagram-Profil analysieren
```python
from ig_complete import InstagramFullScraper

scraper = InstagramFullScraper()
report = scraper.generate_full_report("instagram")

# Ergebnis: instagram_FULL_REPORT.json
```

### Beispiel 2: Facebook-Person suchen
```python
from facebook_analyzer import FacebookProfileAnalyzer

analyzer = FacebookProfileAnalyzer()
profiles = analyzer.search_person("Max Mueller")

for profile in profiles[:5]:
    print(f"{profile['name']}: {profile['url']}")
```

### Beispiel 3: Gel√∂schte Facebook-Inhalte wiederherstellen
```python
from facebook_advanced_scraper import AdvancedFacebookScraper

scraper = AdvancedFacebookScraper(use_delays=True)
report = scraper.analyze_profile_advanced("username")

# Archivierte Versionen abrufen
for snapshot in report['archive_org']['snapshots']:
    print(snapshot['url'])
```

### Beispiel 4: Profilbild reverse-suchen
```python
results = scraper.reverse_image_search("https://example.com/image.jpg")

print(results['google_images'])   # Google Images
print(results['tineye'])          # TinEye
print(results['yandex'])          # Yandex Images
```

---

## üìä WAS WIRD EXTRAHIERT?

### INSTAGRAM
‚úÖ Profildaten (Name, Bio, Follower, Website)
‚úÖ Posts (Text, Likes, Kommentare, Datum)
‚úÖ Kommentare (Autor, Text, Likes)
‚úÖ Likes (Anzahl, Sample Nutzer)
‚úÖ Hashtags (bis zu 50)
‚úÖ Erw√§hnungen (bis zu 50)
‚úÖ Engagement-Statistiken (√ò Likes, Kommentare, Rate)

### FACEBOOK
‚úÖ Profildaten (Name, Bio, Lokation, Arbeit, Schule)
‚úÖ Posts (teilweise √∂ffentlich)
‚úÖ Kommentare (√∂ffentliche)
‚úÖ Likes (√∂ffentliche)
‚úÖ Erw√§hnungen
‚úÖ Gel√∂schte Inhalte (via Archive.org & Google Cache)
‚úÖ Reverse Image Search (Links zu Duplikaten)

---

## ‚öôÔ∏è KONFIGURATION

### Verz√∂gerungen einstellen (respektful scraping)
```python
scraper = AdvancedFacebookScraper(use_delays=True)  # Aktiviert
scraper = AdvancedFacebookScraper(use_delays=False) # Schnell (risky!)
```

### Proxy verwenden
```python
proxy = {
    'http': 'http://proxy.example.com:8080',
    'https': 'http://proxy.example.com:8080'
}
scraper = AdvancedFacebookScraper(proxy=proxy)
```

### Custom User-Agent
```python
scraper.session.headers.update({
    'User-Agent': 'Your Custom User-Agent'
})
```

---

## üîç TECHNIKEN ZUM UMGEHEN VON BLOCKADEN

### 1. Rate Limiting
**Problem:** Zu viele Requests werden blockiert
**L√∂sung:**
```python
scraper = AdvancedFacebookScraper(use_delays=True)  # Automatische Verz√∂gerung
```

### 2. Private Profile
**Problem:** Private Daten nicht sichtbar
**L√∂sung:**
- Archive.org f√ºr √§ltere √∂ffentliche Versionen
- Reverse Image Search
- Mit echtem Account scrapen

### 3. IP-Ban
**Problem:** Zu viele Requests von einer IP
**L√∂sung:**
```python
proxy = {'http': 'socks5://127.0.0.1:9050'}  # Tor oder VPN
scraper = AdvancedFacebookScraper(proxy=proxy)
```

### 4. Gel√∂schte Inhalte
**Problem:** Seite wurde gel√∂scht
**L√∂sung:**
```python
archive_data = scraper.get_from_archive_org("username")
cache_data = scraper.get_from_google_cache("username")
```

---

## üìà AUSGABE-FORMATE

Alle Reports werden als **JSON-Dateien** gespeichert:

```
instagram_username_FULL_REPORT.json
facebook_username_FULL_REPORT.json
facebook_username_ADVANCED_REPORT.json
```

**Struktur:**
```json
{
  "target": "username",
  "timestamp": "2025-11-16T08:04:11",
  "profile": { ... },
  "posts": [ ... ],
  "comments": [ ... ],
  "engagement": { ... },
  "archive_org": { ... },
  "google_cache": { ... }
}
```

---

## üìö ABH√ÑNGIGKEITEN

```bash
pip install requests beautifulsoup4
```

Das ist alles was du brauchst!

---

## ‚ö†Ô∏è LEGALE & ETHISCHE HINWEISE

‚úÖ **ERLAUBT:**
- √ñffentliche Daten scrapen
- Archive.org nutzen
- Reverse Image Search
- Zu Bildungszwecken

‚ùå **NICHT ERLAUBT:**
- Private Nachrichten abrufen
- Passw√∂rter hacken
- Personal Data zu Missbrauch nutzen
- Spam/Phishing
- DSGVO Verletzung

---

## üÜò FEHLERBEHANDLUNG

### "Status 404" Fehler
```
Profil existiert nicht oder URL falsch
‚Üí √úberpr√ºfe Benutzernamen
‚Üí Versuche manuelle URL
```

### "Rate Limit Hit"
```
Zu viele Requests
‚Üí Aktiviere Delays: use_delays=True
‚Üí Nutze Proxy
‚Üí Warte ein paar Stunden
```

### "Private Profile"
```
Kein Zugriff auf private Daten
‚Üí Nutze Archive.org f√ºr alte Versionen
‚Üí Versuche Reverse Image Search
‚Üí Mit eigenem Account scrapen
```

---

## üìû SUPPORT & RESSOURCEN

- **BeautifulSoup Docs:** https://www.crummy.com/software/BeautifulSoup/
- **Requests Docs:** https://requests.readthedocs.io
- **Archive.org API:** https://archive.org/help/wayback_api.php
- **Facebook Privacy:** https://www.facebook.com/privacy

---

## üìù BEISPIEL-WORKFLOW

```
1. Starte Skript
   python facebook_analyzer.py

2. Eingabe-Name eingeben
   "Max Mueller"

3. Script sucht Profile
   ‚Üí Findet mehrere Matches

4. Analysiert bestes Match
   ‚Üí Extrahiert √∂ffentliche Daten
   ‚Üí Sucht Archive.org
   ‚Üí Generiert Report

5. Speichert Daten
   ‚Üí facebook_maxmueller_FULL_REPORT.json

6. √ñffne Report
   ‚Üí Alle Informationen im JSON Format
```

---

**‚öñÔ∏è Disclaimer: Dieses Tool dient zu Bildungs- und Forschungszwecken. Nutzer sind verantwortlich f√ºr die Einhaltung aller lokalen Gesetze und Plattform-ToS.**

Viel Erfolg! üöÄ
